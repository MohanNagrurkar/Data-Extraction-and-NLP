# Data-Extraction-and-NLP
The objective of this assignment is to extract textual data articles from the given URL and perform text analysis to compute variables. 

ğŸš€ Automating Web Content Analysis with Python ğŸš€

Hey everyone, 
Iâ€™m excited to share a recent project for the firm where I developed a comprehensive Python script to automate the process of extracting, cleaning, and analyzing web content. Here's a breakdown of what it does:

ğŸ” 1. Extracting Content from URLs
Using the newspaper3k library, the script downloads and parses articles from given URLs. This allows us to focus only on the main content, skipping over ads, menus, and other unnecessary elements.

ğŸ§¹ 2. Cleaning the Text
The script removes punctuation and stop words from the text, leaving us with the essential words. This step is crucial for accurate analysis.

ğŸ’¡ 3. Sentiment Analysis
By comparing the words in the cleaned text with predefined positive and negative word lists, the script calculates sentiment scores:
Positive Score: Number of positive words
Negative Score: Number of negative words

ğŸ“Š 4. Calculating Metrics
Various linguistic metrics are computed to provide deeper insights:
Polarity Score: Measures the positivity or negativity of the text.
Subjectivity Score: Indicates the subjectivity or objectivity of the text.
Average Sentence Length: Number of words per sentence.
Percentage of Complex Words: Proportion of words with more than two syllables.
Fog Index: Readability index based on sentence length and complex word percentage.
Syllable Per Word: Average syllables per word.
Personal Pronouns: Count of personal pronouns (e.g., I, we, my).

ğŸ“ˆ 5. Continuous Update to Excel
The results are continuously updated into an Excel file with a retry mechanism to handle potential file access issues. This ensures that the process is robust and can handle interruptions.

ğŸ”§ How It Works
The script processes URLs from an input Excel file and updates the results in an output Excel file, adding new data as it processes each URL.

ğŸ› ï¸ Tools and Libraries Used
newspaper3k: For web content extraction
pandas: For data manipulation and Excel file operations
re and string: For text processing and cleaning
time: For handling retries and delays

ğŸŒŸ Why This Matters
Automating the analysis of web content saves time and effort, especially when dealing with large datasets. It provides valuable insights into the sentiment and readability of online articles, which can be crucial for research, content strategy, and market analysis.

Iâ€™m thrilled with how this project turned out and eager to see how it can be applied in various fields. If youâ€™re interested in the technical details or have similar projects, feel free to connect and discuss!

Note: This post and GitHub only include shareable documents as permitted by the firm.

#Python #DataScience #WebScraping #SentimentAnalysis #Automation #ContentAnalysis #NaturalLanguageProcessing #NLP #Analytics #DataAnalytics
