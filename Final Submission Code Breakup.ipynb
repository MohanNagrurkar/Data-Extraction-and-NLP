{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab47e1b",
   "metadata": {},
   "source": [
    "# Data Extraction and NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c8d470",
   "metadata": {},
   "source": [
    "The objective of this assignment is to extract textual data articles from the given URL and perform text analysis to compute variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e9d8bd",
   "metadata": {},
   "source": [
    "Step 1: Importing Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1041c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from newspaper import Article\n",
    "import re\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02797b",
   "metadata": {},
   "source": [
    "Step 2: This function loads the Stop Words, Posititve Words and Negative Words text files and words will be extracted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b999dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_list(word_file):\n",
    "    with open(word_file, 'r') as file:\n",
    "        words = file.read().splitlines()\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c3d273",
   "metadata": {},
   "source": [
    "Step 3: This function extracts the required title and main body text from the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e88f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_content_and_title_from_url(url):\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.title, article.text\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve or parse the URL: {e}\")\n",
    "        return \"\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d33b24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30695f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28a7043a",
   "metadata": {},
   "source": [
    "Step 4: This function removes the stopwords from the retrieved text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df41e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, stopwords):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    cleaned_words = [word for word in words if word.lower() not in stopwords]\n",
    "    cleaned_text = ' '.join(cleaned_words)\n",
    "    total_words = len(cleaned_words)\n",
    "    return cleaned_text, total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caa912e",
   "metadata": {},
   "source": [
    "Step 5: This function calculates the 'POSITIVE SCORE' and 'NEGATIVE SCORE' from the cleaned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece57571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment_score(text, positive_words, negative_words):\n",
    "    words = text.split()\n",
    "    positive_score = sum(1 for word in words if word.lower() in positive_words)\n",
    "    negative_score = sum(1 for word in words if word.lower() in negative_words)\n",
    "    return positive_score, negative_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d827e",
   "metadata": {},
   "source": [
    "Step 6: This function calculates the 'POLARITY SCORE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b63baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_polarity_score(positive_score, negative_score):\n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "    return round(polarity_score,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc43ea",
   "metadata": {},
   "source": [
    "Step 7: This function calculates the 'SUBJECTIVITY SCORE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e3f354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_subjectivity_score(positive_score, negative_score, total_words):\n",
    "    subjectivity_score = (positive_score + negative_score) / (total_words + 0.000001)\n",
    "    return round(subjectivity_score,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6586fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f0021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622eacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1840988f",
   "metadata": {},
   "source": [
    "Step 8: This function calculates the average length of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5373a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_sentence_length(text):\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    sentences = [sentence for sentence in sentences if sentence.strip()]\n",
    "    num_sentences = len(sentences)\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    num_words = len(words)\n",
    "    return num_words / num_sentences if num_sentences > 0 else 0, num_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9be6097",
   "metadata": {},
   "source": [
    "Step 9: This function calculates the syllable count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83db4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    vowels = \"aeiou\"\n",
    "    count = 0\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b413fe7a",
   "metadata": {},
   "source": [
    "Step 10: This function calculates the count of complex words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca34f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_complex_words(text):\n",
    "    words = text.split()\n",
    "    complex_words = [word for word in words if syllable_count(word) > 2]\n",
    "    return len(complex_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a3aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3943d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46f6c240",
   "metadata": {},
   "source": [
    "Step 11: This function calculates the percentage of complex words within the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc7dcc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentage_complex_words(complex_word_count, total_words):\n",
    "    percentage_complex_words = complex_word_count / (total_words + 0.000001)\n",
    "    return round(percentage_complex_words,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef56f13",
   "metadata": {},
   "source": [
    "Step 12: This function calculates the 'FOG INDEX' as per the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a62942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fog_index(avg_sentence_length, percentage_complex_words):\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    return round(fog_index,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f54ec6",
   "metadata": {},
   "source": [
    "Step 13: This function calculates the syllable per word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3477ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_syllable_per_word(text):\n",
    "    words = text.split()\n",
    "    total_syllables = sum(syllable_count(word) for word in words)\n",
    "    syllable_per_word = total_syllables / len(words) if words else 0\n",
    "    return round(syllable_per_word,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f710c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ebb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c452b326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae314f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a7ab7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e965a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2283d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b550040",
   "metadata": {},
   "source": [
    "Step 14: This function calculates the count of personal pronouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03e018f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_personal_pronouns(text):\n",
    "    personal_pronouns = [\"i\", \"we\", \"my\", \"ours\",\"us\"]\n",
    "    # Normalize the text to lower case to make the counting case insensitive\n",
    "    text_lower = text.lower() \n",
    "\n",
    "    # Tokenize the text using regular expressions to capture word boundaries\n",
    "    words = re.findall(r'\\b\\w+\\b', text_lower)\n",
    "\n",
    "    # Count the occurrences of each word in the list\n",
    "    word_counts = Counter(words)\n",
    "    # Get the counts for the specific words\n",
    "    specific_word_counts = {word: word_counts[word] for word in personal_pronouns}\n",
    "    total_count = sum(specific_word_counts.values())\n",
    "    return total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f153e0",
   "metadata": {},
   "source": [
    "Step 15: This function calculates the average length of word within the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "937afacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_word_length(text):\n",
    "    words = text.split()\n",
    "    total_characters = sum(len(word) for word in words)\n",
    "    total_words = len(words)\n",
    "    if total_words == 0:\n",
    "        return 0  # To handle division by zero\n",
    "    avg_length = total_characters / total_words\n",
    "    return round(avg_length,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab26ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b99fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2fcdbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb94c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de3d07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddab543c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef0424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc34efdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf7800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde467f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69cff57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40c10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a1035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3282baf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98026987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93810356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341f4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976ec0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904c4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a458ed89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab66aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e48d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d4242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f41aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c0ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a832b5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b12ec3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce8440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16408e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929687e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbe6097e",
   "metadata": {},
   "source": [
    "Step 16: Code compilation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d60c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_urls_from_excel(excel_file, stopwords_file, positive_words_file, negative_words_file, output_excel_file):\n",
    "    # Load stopwords, positive, and negative words\n",
    "    stopwords = load_word_list(stopwords_file)\n",
    "    positive_words = load_word_list(positive_words_file)\n",
    "    negative_words = load_word_list(negative_words_file)\n",
    "    \n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(excel_file)\n",
    "    \n",
    "    # Ensure the Excel file has the necessary columns\n",
    "    necessary_columns = [\n",
    "        'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', 'SUBJECTIVITY SCORE',\n",
    "        'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX',\n",
    "        'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT',\n",
    "        'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVERAGE WORD COUNT'\n",
    "    ]\n",
    "    \n",
    "    for col in necessary_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0 if 'SCORE' not in col else 0.0\n",
    "            \n",
    "\n",
    "    # Process each URL in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        url_id = row['URL_ID']\n",
    "        url = row['URL']\n",
    "        \n",
    "        # Extract main content and title from the URL\n",
    "        title, text = extract_main_content_and_title_from_url(url)\n",
    "        \n",
    "        # Clean the extracted text\n",
    "        cleaned_text, total_words = clean_text(text, stopwords)\n",
    "        \n",
    "        # Calculate sentiment scores\n",
    "        positive_score, negative_score = calculate_sentiment_score(cleaned_text, positive_words, negative_words)\n",
    "        \n",
    "        # Calculate polarity, subjectivity scores, average sentence length, percentage of complex words, fog index, and average number of words per sentence\n",
    "        avg_sentence_length, num_sentences = calculate_avg_sentence_length(cleaned_text)\n",
    "        complex_word_count = count_complex_words(cleaned_text)\n",
    "        percentage_complex_words = calculate_percentage_complex_words(complex_word_count, total_words)\n",
    "        fog_index = calculate_fog_index(avg_sentence_length, percentage_complex_words)\n",
    "        avg_words_per_sentence = total_words / num_sentences if num_sentences > 0 else 0\n",
    "        syllable_per_word = calculate_syllable_per_word(cleaned_text)\n",
    "        personal_pronouns_count = count_personal_pronouns(cleaned_text)\n",
    "        average_word_length = calculate_average_word_length(cleaned_text)\n",
    "        \n",
    "        # Update the DataFrame with the scores\n",
    "        df.at[index, 'POSITIVE SCORE'] = positive_score\n",
    "        df.at[index, 'NEGATIVE SCORE'] = negative_score\n",
    "        df.at[index, 'POLARITY SCORE'] = calculate_polarity_score(positive_score, negative_score)\n",
    "        df.at[index, 'SUBJECTIVITY SCORE'] = calculate_subjectivity_score(positive_score, negative_score, total_words)\n",
    "        df.at[index, 'AVG SENTENCE LENGTH'] = avg_sentence_length\n",
    "        df.at[index, 'PERCENTAGE OF COMPLEX WORDS'] = percentage_complex_words\n",
    "        df.at[index, 'FOG INDEX'] = fog_index\n",
    "        df.at[index, 'AVG NUMBER OF WORDS PER SENTENCE'] = avg_words_per_sentence\n",
    "        df.at[index, 'COMPLEX WORD COUNT'] = complex_word_count\n",
    "        df.at[index, 'WORD COUNT'] = total_words\n",
    "        df.at[index, 'SYLLABLE PER WORD'] = syllable_per_word\n",
    "        df.at[index, 'PERSONAL PRONOUNS'] = personal_pronouns_count\n",
    "        df.at[index, 'AVERAGE WORD COUNT'] = average_word_length\n",
    "\n",
    "        print(f\"Processed URL {url_id}:\\nPOSITIVE SCORE={positive_score},\\tNEGATIVE SCORE={negative_score},\\tPOLARITY SCORE={df.at[index, 'POLARITY SCORE']},\\tSUBJECTIVITY SCORE={df.at[index, 'SUBJECTIVITY SCORE']},\\nAVG SENTENCE LENGTH={avg_sentence_length},\\tPERCENTAGE OF COMPLEX WORDS={percentage_complex_words},\\tFOG INDEX={fog_index},\\nAVG NUMBER OF WORDS PER SENTENCE={avg_words_per_sentence},\\tCOMPLEX WORD COUNT={complex_word_count},\\tWORD COUNT={total_words},\\tSYLLABLE PER WORD={syllable_per_word},\\nPERSONAL PRONOUNS={personal_pronouns_count},\\tAVERAGE WORD COUNT={average_word_length}\")\n",
    "        print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "    # Save the updated DataFrame back to the Excel file\n",
    "    df.to_excel(output_excel_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c982c67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbbd103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b0a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385c447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb89a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e85284c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8e01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d270f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a87fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dae303ed",
   "metadata": {},
   "source": [
    "Step 17: List of files to be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7e8cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = 'Input.xlsx'  # Input Excel file containing URLs\n",
    "stopwords_file = 'StopWords.txt'  # File containing stopwords\n",
    "positive_words_file = 'positive-words.txt'  # File containing positive words\n",
    "negative_words_file = 'negative-words.txt'  # File containing negative words\n",
    "output_excel_file = 'Output Data Structure.xlsx'  # Output Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9587547",
   "metadata": {},
   "source": [
    "Step 18: Calling main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c36935d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed URL blackassign0001:\n",
      "POSITIVE SCORE=33,\tNEGATIVE SCORE=6,\tPOLARITY SCORE=0.6923,\tSUBJECTIVITY SCORE=0.0698,\n",
      "AVG SENTENCE LENGTH=559.0,\tPERCENTAGE OF COMPLEX WORDS=0.2576,\tFOG INDEX=223.703,\n",
      "AVG NUMBER OF WORDS PER SENTENCE=559.0,\tCOMPLEX WORD COUNT=144,\tWORD COUNT=559,\tSYLLABLE PER WORD=2.0054,\n",
      "PERSONAL PRONOUNS=9,\tAVERAGE WORD COUNT=6.5617\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Processed URL blackassign0002:\n",
      "POSITIVE SCORE=58,\tNEGATIVE SCORE=31,\tPOLARITY SCORE=0.3034,\tSUBJECTIVITY SCORE=0.1122,\n",
      "AVG SENTENCE LENGTH=806.0,\tPERCENTAGE OF COMPLEX WORDS=0.3934,\tFOG INDEX=322.5574,\n",
      "AVG NUMBER OF WORDS PER SENTENCE=793.0,\tCOMPLEX WORD COUNT=312,\tWORD COUNT=793,\tSYLLABLE PER WORD=2.396,\n",
      "PERSONAL PRONOUNS=12,\tAVERAGE WORD COUNT=7.4439\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Processed URL blackassign0003:\n",
      "POSITIVE SCORE=38,\tNEGATIVE SCORE=24,\tPOLARITY SCORE=0.2258,\tSUBJECTIVITY SCORE=0.0997,\n",
      "AVG SENTENCE LENGTH=625.0,\tPERCENTAGE OF COMPLEX WORDS=0.5032,\tFOG INDEX=250.2013,\n",
      "AVG NUMBER OF WORDS PER SENTENCE=622.0,\tCOMPLEX WORD COUNT=313,\tWORD COUNT=622,\tSYLLABLE PER WORD=2.6817,\n",
      "PERSONAL PRONOUNS=0,\tAVERAGE WORD COUNT=8.283\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Processed URL blackassign0004:\n",
      "POSITIVE SCORE=37,\tNEGATIVE SCORE=75,\tPOLARITY SCORE=-0.3393,\tSUBJECTIVITY SCORE=0.1824,\n",
      "AVG SENTENCE LENGTH=619.0,\tPERCENTAGE OF COMPLEX WORDS=0.4642,\tFOG INDEX=247.7857,\n",
      "AVG NUMBER OF WORDS PER SENTENCE=614.0,\tCOMPLEX WORD COUNT=285,\tWORD COUNT=614,\tSYLLABLE PER WORD=2.4967,\n",
      "PERSONAL PRONOUNS=0,\tAVERAGE WORD COUNT=8.0684\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "--*--*--Program Ended--*--*--\n"
     ]
    }
   ],
   "source": [
    "process_urls_from_excel(excel_file, stopwords_file, positive_words_file, negative_words_file, output_excel_file)\n",
    "print(\"--*--*--Program Ended--*--*--\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
