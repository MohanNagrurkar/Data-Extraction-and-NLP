{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b8bc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed URL blackassign0001:\n",
      "POSITIVE SCORE=33,\tNEGATIVE SCORE=6,\tPOLARITY SCORE=0.6923,\tSUBJECTIVITY SCORE=0.0698,\n",
      "AVG SENTENCE LENGTH=559.0,\tPERCENTAGE OF COMPLEX WORDS=0.2576,\tFOG INDEX=223.703,\n",
      "AVG NUMBER OF WORDS PER SENTENCE=559.0,\tCOMPLEX WORD COUNT=144,\tWORD COUNT=559,\tSYLLABLE PER WORD=2.0054,\n",
      "PERSONAL PRONOUNS=0,\tAVERAGE WORD COUNT=6.5617\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Processed URL blackassign0002:\n",
      "POSITIVE SCORE=58,\tNEGATIVE SCORE=31,\tPOLARITY SCORE=0.3034,\tSUBJECTIVITY SCORE=0.1122,\n",
      "AVG SENTENCE LENGTH=806.0,\tPERCENTAGE OF COMPLEX WORDS=0.3934,\tFOG INDEX=322.5574,\n",
      "AVG NUMBER OF WORDS PER SENTENCE=793.0,\tCOMPLEX WORD COUNT=312,\tWORD COUNT=793,\tSYLLABLE PER WORD=2.396,\n",
      "PERSONAL PRONOUNS=0,\tAVERAGE WORD COUNT=7.4439\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Processed URL blackassign0003:\n",
      "POSITIVE SCORE=38,\tNEGATIVE SCORE=24,\tPOLARITY SCORE=0.2258,\tSUBJECTIVITY SCORE=0.0997,\n",
      "AVG SENTENCE LENGTH=625.0,\tPERCENTAGE OF COMPLEX WORDS=0.5032,\tFOG INDEX=250.2013,\n",
      "AVG NUMBER OF WORDS PER SENTENCE=622.0,\tCOMPLEX WORD COUNT=313,\tWORD COUNT=622,\tSYLLABLE PER WORD=2.6817,\n",
      "PERSONAL PRONOUNS=0,\tAVERAGE WORD COUNT=8.283\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Processed URL blackassign0004:\n",
      "POSITIVE SCORE=37,\tNEGATIVE SCORE=75,\tPOLARITY SCORE=-0.3393,\tSUBJECTIVITY SCORE=0.1824,\n",
      "AVG SENTENCE LENGTH=619.0,\tPERCENTAGE OF COMPLEX WORDS=0.4642,\tFOG INDEX=247.7857,\n",
      "AVG NUMBER OF WORDS PER SENTENCE=614.0,\tCOMPLEX WORD COUNT=285,\tWORD COUNT=614,\tSYLLABLE PER WORD=2.4967,\n",
      "PERSONAL PRONOUNS=0,\tAVERAGE WORD COUNT=8.0684\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "--*--*--Program Ended--*--*--\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from newspaper import Article\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def load_word_list(word_file):\n",
    "    with open(word_file, 'r') as file:\n",
    "        words = file.read().splitlines()\n",
    "    return set(words)\n",
    "\n",
    "def extract_main_content_and_title_from_url(url):\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.title, article.text\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve or parse the URL: {e}\")\n",
    "        return \"\", \"\"\n",
    "\n",
    "def clean_text(text, stopwords):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    cleaned_words = [word for word in words if word.lower() not in stopwords]\n",
    "    cleaned_text = ' '.join(cleaned_words)\n",
    "    total_words = len(cleaned_words)\n",
    "    return cleaned_text, total_words\n",
    "\n",
    "def calculate_sentiment_score(text, positive_words, negative_words):\n",
    "    words = text.split()\n",
    "    positive_score = sum(1 for word in words if word.lower() in positive_words)\n",
    "    negative_score = sum(1 for word in words if word.lower() in negative_words)\n",
    "    return positive_score, negative_score\n",
    "\n",
    "def calculate_polarity_score(positive_score, negative_score):\n",
    "    score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "    return round(score,4)\n",
    "\n",
    "def calculate_subjectivity_score(positive_score, negative_score, total_words):\n",
    "    subjectivity_score = (positive_score + negative_score) / (total_words + 0.000001)\n",
    "    return round(subjectivity_score,4)\n",
    "\n",
    "def calculate_avg_sentence_length(text):\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    sentences = [sentence for sentence in sentences if sentence.strip()]\n",
    "    num_sentences = len(sentences)\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    num_words = len(words)\n",
    "    return num_words / num_sentences if num_sentences > 0 else 0, num_sentences\n",
    "\n",
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    vowels = \"aeiou\"\n",
    "    count = 0\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "def count_complex_words(text):\n",
    "    words = text.split()\n",
    "    complex_words = [word for word in words if syllable_count(word) > 2]\n",
    "    return len(complex_words)\n",
    "\n",
    "def calculate_percentage_complex_words(complex_word_count, total_words):\n",
    "    percentage_complex_words = complex_word_count / (total_words + 0.000001)\n",
    "    return round(percentage_complex_words,4)\n",
    "\n",
    "def calculate_fog_index(avg_sentence_length, percentage_complex_words):\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    return round(fog_index,4)\n",
    "\n",
    "def calculate_syllable_per_word(text):\n",
    "    words = text.split()\n",
    "    total_syllables = sum(syllable_count(word) for word in words)\n",
    "    syllable_per_word = total_syllables / len(words) if words else 0\n",
    "    return round(syllable_per_word,4)\n",
    "\n",
    "def count_personal_pronouns(text):\n",
    "    personal_pronouns = [\"i\", \"we\", \"my\", \"ours\",\"us\"]\n",
    "    text_lower = text.lower() \n",
    "    words = re.findall(r'\\b\\w+\\b', text_lower)\n",
    "    word_counts = Counter(words)\n",
    "    specific_word_counts = {word: word_counts[word] for word in personal_pronouns}\n",
    "    total_count = sum(specific_word_counts.values())\n",
    "    return total_count\n",
    "\n",
    "def calculate_average_word_length(text):\n",
    "    words = text.split()\n",
    "    total_characters = sum(len(word) for word in words)\n",
    "    total_words = len(words)\n",
    "    if total_words == 0:\n",
    "        return 0  # To handle division by zero\n",
    "    avg_length = total_characters / total_words\n",
    "    return round(avg_length,4)\n",
    "\n",
    "def process_urls_from_excel(excel_file, stopwords_file, positive_words_file, negative_words_file, output_excel_file):\n",
    "    stopwords = load_word_list(stopwords_file)\n",
    "    positive_words = load_word_list(positive_words_file)\n",
    "    negative_words = load_word_list(negative_words_file)\n",
    "    \n",
    "    df = pd.read_excel(excel_file)\n",
    "    \n",
    "    necessary_columns = [\n",
    "        'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', 'SUBJECTIVITY SCORE',\n",
    "        'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX',\n",
    "        'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT',\n",
    "        'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVERAGE WORD COUNT']\n",
    "    \n",
    "    for col in necessary_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0 if 'SCORE' not in col else 0.0\n",
    "            \n",
    "    for index, row in df.iterrows():\n",
    "        url_id = row['URL_ID']\n",
    "        url = row['URL']\n",
    "        \n",
    "        title, text = extract_main_content_and_title_from_url(url)\n",
    "        \n",
    "        cleaned_text, total_words = clean_text(text, stopwords)\n",
    "        \n",
    "        positive_score, negative_score = calculate_sentiment_score(cleaned_text, positive_words, negative_words)\n",
    "        \n",
    "        avg_sentence_length, num_sentences = calculate_avg_sentence_length(cleaned_text)\n",
    "        complex_word_count = count_complex_words(cleaned_text)\n",
    "        percentage_complex_words = calculate_percentage_complex_words(complex_word_count, total_words)\n",
    "        fog_index = calculate_fog_index(avg_sentence_length, percentage_complex_words)\n",
    "        avg_words_per_sentence = total_words / num_sentences if num_sentences > 0 else 0\n",
    "        syllable_per_word = calculate_syllable_per_word(cleaned_text)\n",
    "        personal_pronouns_count = count_personal_pronouns(cleaned_text)\n",
    "        average_word_length = calculate_average_word_length(cleaned_text)\n",
    "        \n",
    "        df.at[index, 'POSITIVE SCORE'] = positive_score\n",
    "        df.at[index, 'NEGATIVE SCORE'] = negative_score\n",
    "        df.at[index, 'POLARITY SCORE'] = calculate_polarity_score(positive_score, negative_score)\n",
    "        df.at[index, 'SUBJECTIVITY SCORE'] = calculate_subjectivity_score(positive_score, negative_score, total_words)\n",
    "        df.at[index, 'AVG SENTENCE LENGTH'] = avg_sentence_length\n",
    "        df.at[index, 'PERCENTAGE OF COMPLEX WORDS'] = percentage_complex_words\n",
    "        df.at[index, 'FOG INDEX'] = fog_index\n",
    "        df.at[index, 'AVG NUMBER OF WORDS PER SENTENCE'] = avg_words_per_sentence\n",
    "        df.at[index, 'COMPLEX WORD COUNT'] = complex_word_count\n",
    "        df.at[index, 'WORD COUNT'] = total_words\n",
    "        df.at[index, 'SYLLABLE PER WORD'] = syllable_per_word\n",
    "        df.at[index, 'PERSONAL PRONOUNS'] = personal_pronouns_count\n",
    "        df.at[index, 'AVERAGE WORD COUNT'] = average_word_length\n",
    "\n",
    "        print(f\"Processed URL {url_id}:\\nPOSITIVE SCORE={positive_score},\\tNEGATIVE SCORE={negative_score},\\tPOLARITY SCORE={df.at[index, 'POLARITY SCORE']},\\tSUBJECTIVITY SCORE={df.at[index, 'SUBJECTIVITY SCORE']},\\nAVG SENTENCE LENGTH={avg_sentence_length},\\tPERCENTAGE OF COMPLEX WORDS={percentage_complex_words},\\tFOG INDEX={fog_index},\\nAVG NUMBER OF WORDS PER SENTENCE={avg_words_per_sentence},\\tCOMPLEX WORD COUNT={complex_word_count},\\tWORD COUNT={total_words},\\tSYLLABLE PER WORD={syllable_per_word},\\nPERSONAL PRONOUNS={personal_pronouns_count},\\tAVERAGE WORD COUNT={average_word_length}\")\n",
    "        print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "        \n",
    "    df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "excel_file = 'Input.xlsx'  # Input Excel file containing URLs\n",
    "stopwords_file = 'StopWords.txt'  # File containing stopwords\n",
    "positive_words_file = 'positive-words.txt'  # File containing positive words\n",
    "negative_words_file = 'negative-words.txt'  # File containing negative words\n",
    "output_excel_file = 'Output Data Structure.xlsx'  # Output Excel file\n",
    "\n",
    "process_urls_from_excel(excel_file, stopwords_file, positive_words_file, negative_words_file, output_excel_file)\n",
    "\n",
    "print(\"--*--*--Program Ended--*--*--\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
